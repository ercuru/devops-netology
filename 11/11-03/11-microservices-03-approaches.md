# Домашнее задание к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку
>
> Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
> Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.
> 
> Решение должно соответствовать следующим требованиям:
> - Облачная система;
>- Система контроля версий Git;
>- Репозиторий на каждый сервис;
>- Запуск сборки по событию из системы контроля версий;
>- Запуск сборки по кнопке с указанием параметров;
>- Возможность привязать настройки к каждой сборке;
>- Возможность создания шаблонов для различных конфигураций сборок;
>- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
>- Несколько конфигураций для сборки из одного репозитория;
>- Кастомные шаги при сборке;
>- Собственные докер образы для сборки проектов;
>- Возможность развернуть агентов сборки на собственных серверах;
>- Возможность параллельного запуска нескольких сборок;
>- Возможность параллельного запуска тестов;
>
>Обоснуйте свой выбор.

### Решение 1: Обеспечить разработку

Под требования приведенные выше можно использовать [GitLab](https://about.gitlab.com) ( с *GitLab CI/CD* + *Gitlab Runner*).  
  
**GitLab** - облачная платформа контроля версий. Позволяет создавать репозитории для каждого сервиса.
  
**GitLab Ci/CD** - инструмент непрерывной интеграции и поставки, интегрируемый в систему контроля версий *GitLab*.

Позволяет:
- запускать сборку по событию (по коммиту в определённой ветке)
- запускать сборку вручную (по кнопке с указанием ветки, тэга, переменных окружения и др.)
- привязать настройки для каждой сборки переменными окружения или с помощью описания в конфигурационном файле `.gitlab-ci.yml`
- создавать шаблоны для различных конфигураций сборок в файле `.gitlab-ci.yml`, которые могут храниться в хранилище шаблонов, репозитории проекта, глобальной конфигурации *GitLab* или внешнем хранилище
- хранить пароли и ключи доступа в зашифрованном виде в переменных окружения
- запускать несколько конфигураций сборки, описав их в файле конфигурации отдельными *job*
- использовать кастомные шаги при сборке с помощью скриптов
- создавать Docker-образы на основе Dockerfile, в который будет вложен артефакт, полученный в результате сборки  
  
**GitLab Runner** - агент устанавливаемый на отдельные сервера для выполнения задач поступающих от *GitLab CI/CD*.

Позволяет:
- параллельно запускать несколько сборок на доступных машинах, где установлен *Runner*
- параллельно запускать несколько тестов на доступных машинах, где установлен *Runner*

## Задача 2: Логи
>
>Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
>Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.
>
>Решение должно соответствовать следующим требованиям:
>- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
>- Минимальные требования к приложениям, сбор логов из stdout;
>- Гарантированная доставка логов до центрального хранилища;
>- Обеспечение поиска и фильтрации по записям логов;
>- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
>- Возможность дать ссылку на сохраненный поиск по записям логов;
>
>Обоснуйте свой выбор.

### Решение 2: Логи

Как стандарт, можно использовать **ELK-стек**, включающий *Elasticsearch*, *Logstash* и *Kibana*  

**Elasticsearch** - инструмент сбора, хранения и анализа логов. В *ELK-стеке* он также выступает в качестве централизованного хранилища логов.  
С помощью языка запросов *Query DSL* в *Elasticsearch* можно производить поиск и фильтрацию информации по логам.

**Logstash** - средство сбора логов. Собирает логи со всех хостов обслуживающих систему. Может принимать логи из разных источников, в том числе *stdout* приложений и отправлять их в централизованное хранилище. 
Гарантировать доставку логов в *ELK-стеке* можно за счёт безопасного соединения HTTPS между *Logstash* и *Elasticsearch*, подтверждения доставки, буферизация, очередей и др.
  
**Kibana** - инструмент визуализации и анализа логов. Предоставляет разработчикам дашборды, графики и другие инструменты для поиска и анализа логов. Также *Kibana* позволяет сохранить ссылку на поиск по логам.


## Задача 3: Мониторинг
>
> Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
> Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.
> 
> Решение должно соответствовать следующим требованиям:
> - Сбор метрик со всех хостов, обслуживающих систему;
> - Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
> - Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
> - Сбор метрик, специфичных для каждого сервиса;
> - Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
> - Пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы;
> 
> Обоснуйте свой выбор

### Решение 3: Мониторинг

Одним из популярных вариантов, под описанные требования, можно предложить следующий стек продуктов:  
1. **Node Exporter** - это агент устанавливаемый на хосты, собирающий метрики состояния и потребляемых ресурсов CPU, RAM, HDD, Network и др. Также существуют экспортеты собирающие метрики конкретных сервисов (**Nginx Exporter**, **MySQL/PostgreSQL Exporter** и т.д.)
2. **Prometheus** - система мониторинга, сбора и хранения метрик, полученных от экспортеров наблюдаемых сервисов.
3. **Grafana** - инструмент визуализации данных мониторинга. Предоставляет пользовательский интерфейс для создания запросов и агрегирования информации. Позволяет создавать графики, диаграммы и уведомления на основе собранных в *Prometheus* метрик.

